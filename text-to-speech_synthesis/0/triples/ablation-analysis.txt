(Contribution||has||Ablation analysis)
(Ablation analysis||study||effect of ensemble teacher model in knowledge distillation)
(effect of ensemble teacher model in knowledge distillation||boost||accuracy)
(accuracy||by||more than 1 % WER)
(accuracy||compared with||single teacher model ( a Transformer model with 6 - layer encoder and 6 - layer decoder ))
(Ablation analysis||study||effect of distilling from unlabeled source words)
(effect of distilling from unlabeled source words||boost||accuracy)
(accuracy||by||nearly 1 % WER)
(accuracy||demonstrating the effectiveness by||introducing abundant unlabeled data)
(introducing abundant unlabeled data||into||knowledge distillation)
(Ablation analysis||compare||Transformer)
(Transformer||with||RNN and CNN based models)
(Transformer||without using||knowledge distillation and unlabeled data)
(Transformer||outperforms||RNN and CNN based models)

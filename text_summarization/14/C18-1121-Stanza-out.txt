title
Ensure the Correctness of the Summary : Incorporate Entailment Knowledge into Abstractive Sentence Summarization
abstract
In this paper , we investigate the sentence summarization task that produces a summary from a source sentence .
Neural sequence - to - sequence models have gained considerable success for this task , while most existing approaches only focus on improving word overlap between the generated summary and the reference , which ignore the correctness , i.e. , the summary should not contain error messages with respect to the source sentence .
We argue that correctness is an essential requirement for summarization systems .
Considering a correct summary is semantically entailed by the source sentence , we incorporate entailment knowledge into abstractive summarization models .
We propose an entailment - aware encoder under multi-task framework ( i.e. , summarization generation and entailment recognition ) and an entailment - aware decoder by entailment Reward Augmented Maximum Likelihood ( RAML ) training .
Experimental results demonstrate that our models significantly outperform baselines from the aspects of informativeness and correctness .
This work is licensed under a Creative Commons Attribution 4.0 International License .
License details : http:// creativecommons.org/licenses/by/4.0/.
Introduction
Sentence summarization is a well - studied task that creates a condensed version of along source sentence .
Sequence - to - sequence ( seq2seq ) model that encodes a source sequence into a latent representation and outputs another sequence is the dominating framework for sentence summarization .
Despite substantial improvements on this task , most of the existing researches typically aim to improve word overlap between the generated summary and the references , which is measured by n-gram matching metrics ( e.g. , ROUGE ) .
Hence , it can not guarantee the semantic correctness of the summary as a whole .
Therefore , in some cases , the summary giving high matching scores may contain critical error messages , which makes the summary fail to capture the correct information with respect to the source sentence .
Previous study shows that about 30 % of the summaries generated by state - of - the - art seq2seq system are subject to this problem .
Here is an example ( the digits are replaced by " # " ) :
Source sentence : franch won the gold medal at women 's epee team event of the fie #### world championships by beating china ## -# # .
Reference : france beats china for women 's epee team gold State - of - the - art seq2seq model : canada wins women 's epee team event
For the example shown above , the seq2seq system produces a fluent summary which contains an obvious mistake .
The true winner of the " women 's epee team event " is " france " , while the summarization model wrongly generates " canada " , which is probably due to similar word representations for country names .
Though the word overlap between the generated summary and the reference is considerable , leading to high ROUGE scores , the summary is invalid .
We argue that correctness is an essential requirement for summarization systems , while most existing systems ignore it .
Generally , a correct summary is semantically entailed by the source sentence , thus we believe entailment 1 knowledge is beneficial to avoid producing contradictory or unrelated information in the summary .
To incorporate entailment knowledge into abstractive summarization models , we propose in this work an entailment - aware encoder and an entailment - aware decoder .
We share the encoder of the summarization generation system with the entailment recognition system , so that the encoder can grasp both the gist of the source sentence and be aware of entailment relationships .
Furthermore , we propose an entailment Reward Augmented Maximum Likelihood ( RAML ) training that encourages the decoder of the summarization system to produce summary entailed by the source .
Experimental results demonstrate that our models significantly outperform some solid baselines on objective evaluation for informativeness and manual evaluation for correctness .
Further analysis suggests that our summarization model is aware of entailment knowledge .
Our main contributions are as follows :
We incorporate entailment knowledge into summarization models to avoid producing unrelated information with respect to the source sentence .
We propose an entailment - aware encoder by jointly modeling summarization generation and entailment recognition .
We introduce an entailment - aware decoder via entailment RAML training .
Background : Seq2seq Learning
In this section , we describe the basic seq2seq learning framework .
Given a dataset of input-output pairs ,
, the seq2seq model maximizes the conditional probability of a target sequence y * : p ( y * | x ) .
Recurrent Neural Networks ( RNN ) encoder reads and converts a variablelength input sequence x into a context representation c as follows :
where ht ?
Rn is a hidden state at time t , and ct is a context vector generated from the sequence of the hidden states .
f enc and f care nonlinear activation functions .
The decoder generates wordy t given the context vector ct and the previously generated words :
where st is the hidden state of the decoder and f dec is a nonlinear activation function .
The maximum likelihood ( ML ) framework tries to minimize negative log - likelihood of the parameters as follows :
3 Our Proposed Model
Overview
In order to avoid generating unrelated summary with respect to the source sentence , we propose two strategies to incorporate entailment knowledge into seq2seq summarization model .
We first introduce an entailment - aware encoder using multi-task learning for summarization generation and entailment recognition .
Then , we introduce an entailment - aware decoder by entailment RAML training . :
The framework of our model .
Entailment - aware encoder is learned by jointly training summarization generation ( left part of ( a ) , which is a seq2seq model ) and entailment recognition ( right part of ( a ) , in which sentence pair in the entailment recognition corpus are encoded as u and v) .
Entailmentaware decoder is learned by entailment RAML training , in which the summary will be rewarded if it is entailed by the source sentence .
Shared Sentence Encoder
Given a source sentence x = ( x 1 , , x n ) , we employ a bidirectional LSTM ( BiLSTM ) to build its hidden representation ( h 1 , , h n ) .
The BiLSTM encodes source sentence forwardly and backwardly to generate two sequences of the hidden states :
The final sentence representation hi is the concatenation of the forward and backward vectors :
Entailment - aware Encoder
In this section , we propose a multi-task learning for abstractive summarization by sharing the encoder with the task of entailment recognition .
By doing so , we can learn an entailment - aware encoder for sentence summarization task .
In this way , we can improve the correctness aspect of the summarization model , while maintaining the salient information extraction aspects .
Note that the training data for summarization and entailment task is from summarization and entailment corpus , respectively .
Attention - based Summarization
Decoder
At each time step t , the state of the decoder st is calculated as follows :
We compute the context vector ct as a weighted sum of the source annotations as follows :
where each vector is weighted by the attention weight ?
t , i , as calculated in Equations 10 and 11:
The probability for the next target wordy t is computed using hidden state st and the previously emitted wordy t?1 as follows :
where W h , W s , W e , Le , L sand L y are model parameters .
The summarization model is trained by minimizing negative log - likelihood loss as in Equation 4 .
Matching - based Entailment Inference Model
To infer entailment relation , input sentence pairs from the entailment recognition corpus are fed into sentence encoder to obtain hidden representation ( h u 1 , , h u n ) and ( h v 1 , , h v n ) , respectively .
Then , the sentence pairs are encoded as vectors
, respectively .
Next , the absolute difference and the element - wise product for the tuple are concatenated with the original vectors u and v as follows :
We then feed q into a 3 - layer multilayer perceptron ( MLP ) classifier .
The 3 - class softmax output layer is on top of MLP .
The entailment recognition model is trained by minimizing cross - entropy loss .
Multi - Task Learning ( MTL )
In our multi-task setup , we share the encoder parameters of both the tasks , as shown in ( a ) .
Traditional MTL considers equal contribution for all tasks .
In our model , two tasks are significantly different .
The summary generation task is much more complicated than entailment recognition , leading to different learning difficulties and convergence rates .
Therefore , summarization generation is regarded as the main task and entailment recognition as the auxiliary task , and our goal is to optimize the main task with assistance of auxiliary task .
To this end , we optimize the two loss functions alternatively during training .
Let ?
be the number of mini-batches of training for entailment recognition after 100 mini-batches of training for summarization generation .
We adopt ? = 10 and performance with different ?
is discussed in Section 6.6.3 .
Entailment - aware Decoder
In order to encourage the decoder of the summarization system to produce summary entailed by the source sentence , we apply an entailment - aware decoder by entailment RAML training .
Reward Augmented Maximum Likelihood ( RAML ) Training
RAML provides a computationally efficient approach to optimize task - specific reward ( loss ) directly .
In our work , we apply RAML to incorporate entailment - based reward into our summarization model , as shown in
The RAML objective function is defined as follows :
where Y is the set of possible model outputs .
r ( x , y , y * ) denotes the reward function and ?
is the regularization parameter .
Optimizing by Entailment - based Sampling
We can express the gradient of L RAML in terms of an expectation over samples from q ( y|x , y * ; ? ) :
RAML training adds a sampling step over typical ML objective .
Instead of optimizing ML on training samples , given training input ( x , y * ) , RAML training first samples an output y proportionally to the reward .
Then , RAML optimizes log - likelihood on such sample given the corresponding input .
Thus , we need to sample auxiliary outputs from the exponentiated payoff distribution , q ( y|x , y * ; ? ) .
In this work , we first use reward values defined by negative Hamming distance and then re-weight the reward based on entailment reward s ( x , y , y * ) .
Particularly , given a sentence y * of length , we count the number of sentences within an edit distance d , where d ?
{ 0 , . . . , 2 }.
Then , we weight the counts by exp{?d/? } and perform normalization .
Finally , we apply importance sampling by the weight exp{ ( s ( x , y , y * ) + d ) /? } and perform normalization , where the proposal distribution is Hamming distance sampling 2 .
We define entailment reward s ( x , y , y * ) as follows :
where e ( x , y) denotes entailment score for sentence pairs ( x , y ) .
Our goal is to maximize the entailment reward of the summary towards the reference , given the source sentence .
Here we adopt the model of trained on the MultiNLI corpus 3 to obtain e ( x , y ) .
Related work
Text summarization methods can be categorized into extraction - based methods and abstraction - based methods .
first apply the seq2seq model to abstractive sentence summarization .
They propose an attentive CNN encoder and a neural network language model decoder .
use RNN as the decoder and achieve better performance .
further replace the encoder with an RNN , forming a full RNN seq2seq model .
and incorporate a copying mechanism into seq2seq learning and propose a switch gate to control whether to copy from the source or generate a word by the decoder .
Copying mechanism intends to replicate segments in the source to the target , which can not guarantee the correctness of the summary as a whole .
focus on improving the semantic relevance between source and summary by encouraging high similarity of their representation .
employ a selective encoding model to control the information flow from encoder to decoder .
apply a deep recurrent generative decoder to seq2seq framework .
solve the problem of fake facts in a summary .
They use Open Information Extraction to extract fact descriptions in the source sentence and propose the dual - attention seq2seq framework to force the generation conditioned on both source sentence and the fact descriptions .
To the best of our knowledge , our work is the first to directly explore the correctness of summary without any preprocessing .
Some previous work has used textual entailment recognition to reduce redundancy for extractive summarization task .
Our work is partially inspired by the models of with following differences : model the entailment task as the seq2seq generation problem and enforce sharing of the same decoder between summarization and entailment .
However , the entailment task is more reasonable to be considered as a multi-label classification problem rather than a generation problem .
We thus design a multi-task learning framework in which the summarization generation task shares the same encoder with the entailment recognition task .
Dataset
We conduct experiments on English Gigaword and DUC 2004 datasets .
Gigaword Corpus .
We use the annotated Gigaword corpus provided by .
The dataset has about 3.8 million training pairs .
Following , we use 8 , 000 pairs as validation set and the test samples provided by and Word embedding size is set to 300 and LSTM hidden state size is set to 512 .
We use the full source and target vocabularies collected from the training data , which have 119 , 505 and 68 , 885 words , respectively .
Adam ( Kingma and Ba , 2014 ) optimizer is applied with the learning rate of 0.001 , momentum parameters ? 1 = 0.9 and ? 1 = 0.999 , and = 10 ?8 . For RAML , ? = 0.85 . The mini - batch size is set to 64 .
We test the model performance ( ROUGE - 2 F1 score ) on validation set for every 2,000 batches .
We halve the learning rate if the ROUGE - 2 F1 score drops for twelve consecutive tests on validation set .
We also apply gradient clipping with range [ ? 5 , 5 ] during training .
Our model with entailmentaware encode requires less than 300,000 training iterations to train with early stopping .
To speedup the training for our RAML model , we continue the RAML training based on the pre-trained model with ML training with the current decayed learning rate .
At test time , we use beam search with beam size 10 to generate the summary .
We report ROUGE F1 score including ROUGE - 1 , ROUGE - 2 and ROUGE - L for Gigaword corpus and ROUGE recall score for DUC 2004 corpus .
Comparative Methods
We compare a set of sentence summarization baselines .
ABS . first apply the seq2seq model to abstractive sentence summarization .
They use an attentive CNN encoder and neural network language model decoder to summarize sentence .
ABS +. propose a neural machine translation model with two - layer LSTMs for the encoder - decoder .
Seq2seq .
This is a standard seq2seq model with attention mechanism .
Seq2seq + MTL .
This is our proposed model with entailment - aware encoder , which applies a multi-task learning ( MTL ) framework to seq2seq model .
Seq2seq + MTL ( Share decoder ) .
propose a multi - task learning ( MTL ) framework in which the decoder is shared for summarization generation and entailment generation task .
Seq2seq + ERAML .
This is our proposed model with entailment - aware decoder , which conducts an Entailment Reward Augmented Maximum Likelihood ( ERAML ) training framework .
Seq2seq + ROUGE -2 RAML .
We apply ROUGE - 2 RAML training for seq2seq model .
Seq2seq + RL .
We implement Reinforcement Learning ( RL ) models ( policy gradient ) with reward metrics of Entailment and ROUGE - 2 .
Seq2seq + selective .
employ a selective encoding model to control the information flow from encoder to decoder .
To verify the generalization of our entailment - based strategies , we adopt selective encoding mechanism to our seq2seq model and apply MTL and RAML to Seq2seq + selective model , which is denoted as the Seq2seq + selective + MTL + RAML model .
Model
ROUGE - 1 ROUGE - 2 ROUGE-L ABS 37.41 15.87 34.70 Seq2seq 43 .
Our models perform significantly better than baselines by the 95 % confidence interval measured by the official ROUGE script .
Experimental Results : Gigaword Corpus
In .
The comparison to the model of Seq2seq + selective shows that our entailment - aware strategies are also useful for seq2seq model with selective encoding framework , which demonstrates the good generalization of our method .
The results on English Gigaword test set provided by are shown in .
Our model performs better than the previous works .
Experimental Results : DUC 2004
Test Corpus
We evaluate our model with the ROUGE recall score .
The reference summaries of the DUC 2004 test set are fixed to 75 bytes and we set the maximum length of the summary to 18 following .
In , experimental results also show our Seq2seq + selective + MTL + ERAML model achieves significant improvements over baseline models , surpassing Feats2s by 0.98 % ROUGE - 1 , 0.78 % ROUGE - 2 and 0.65 % ROUGE - L without fine - tuning on DUC data .
Manual Evaluation
Next , we conduct a manual evaluation to inspect the correctness of the generated summaries .
We randomly select 500 samples in the test set and employ five postgraduates to classify the generated summaries as correct ( i.e. , not contain wrong information ) or not .
As shown in , 60.6 % of the summaries generated by seq2seq model are correct , and it rises to 69.4 % and 74.2 % for our model with selective encoding and entailment - aware strategies , respectively , which indicates the effectiveness of our model to generate a correct summary .
Test set of DUC 2004 test set Model RG - 1 RG - 2 RG- L RG- 1 RG- 2 RG- L ABS 29.55 11.32 26.42 26.55 7.06 22.05 ABS + 29.76 11.88 26.96 28.18 8.49 23.81 Feats2s 32.67 15.59 30.64 28.35 9.46 24.59 CAs2s 33.78 15.97 31.15 28.97 8.26 24.06 Luong - NMT 33.10 14.45 30.71 28.55 8.79 24.43 Seq2seq 34 : Manual evaluation for correctness .
Further Analysis
To further investigate the effectiveness of our model , we perform analysis on the entailment score improvement , the abstraction degree of our model and the impact for entailment recognition task .
Does our summarization model learn entailment knowledge ?
The motivation of our work is to encourage summarization model to generate summaries thatare entailed by the source sentences .
To verify this goal , we investigate the entailment score for source - summary pairs for different models .
For the test set of , the average entailment score for the reference is 0.72 , while for the basic seq2seq model , the entailment score is only 0.46 .
When we adopt entailmentbased strategies , the entailment score rises to 0.63 for seq2seq model .
Note that the entailment score is 0.57 for seq2seq model with selective encoding , and we believe that the selective mechanism can filter out secondary information in the input , which will reduce the possibility to generate irrelevant information .
Entailment - aware selective model achieves a high entailment reward of 0.71 .
In part at least , we can conclude that our model has successfully learned entailment knowledge .
6.6.2
Is it less abstractive for our model ?
We have shown that our entailment - aware model can generate correct summaries more frequently ( Section 6.5 ) .
Intuitively , it is more likely to be correct if summary segments are directly extracted from the source .
Thus , readers may wonder whether our model is less abstractive .
shows that the seq2seq model produces more novel words ( i.e. , words that do not appear in the article ) than our model , indicating a lower degree of abstraction for our model .
However , when we exclude all the words not in the reference ( these words may lead to wrong information ) , our model generates more novel words , suggesting that our model provides a compromise solution for informativeness and correctness .
Thus , our model can generate summary with fewer mistakes .
6.6.3 Could the entailment recognition also be improved ?
Multi - task learning ( MTL ) involves sharing parameters between related tasks , whereby each task can benefit from extra information of other tasks in the training process .
In this section , we explore whether the entailment recognition can benefit from summarization generation task .
shows that our summarization model with MTL outperforms basic seq2seq model .
As ? increases , the accuracy of entailment recognition improves and finally exceeds that of the model without MTL , which reveals the advantage of MTL framework .
Case Study
We illustrate the examples of outputs in .
As shown in the table , seq2seq model generates summaries thatare not relevant to the source sentence , while the output of our model obtains higher entailment scores than those of seq2seq model .
For the first example , seq2seq model regards the reason for " brazil stocks rise " as " consumer credit concerns " , while in fact , " consumer " is not worried because " government said it would n't impose restraints on consumer credit " .
By contrast , since our model incorporates entailment knowledge , the true reason is captured and the output of our model is related to the source sentence .
A similar problem happens in example 2 , and seq2seq model generates a summary that is contradictory to the source .
The " demonstration " is " denied " by the " authorities " , while seq2seq model confirms the " demonstration " .
In Example 3 , neither seq2seq nor our model performs satisfactorily .
Seq2seq model again misunderstands the meaning of the source and outputs summary containing wrong information .
Though the summary generated by our model is entailed by the source , the summary fails to produce an integrated sentence and misses the key points of the source , such as the object of the event , " queens taxi driver " .
A mixed reward , i.e. , combining entailment and ROUGE - 2 , may address this issue .
We leave it for our future work .
Conclusion
This paper investigates the correctness problem in abstractive summarization .
We propose an entailmentaware encoder by jointly learning summarization generation and entailment recognition .
We present an entailment - aware decoder by entailment reward augmented maximum likelihood training .
By enriching the encoder and decoder with entailment information , our model makes the summary more likely be entailed by the source input .
Experimental results on Gigaword and DUC 2004 datasets demonstrate that our model achieves significant improvements over strong baselines on both informativeness and correctness .
Our code is available online 4 .

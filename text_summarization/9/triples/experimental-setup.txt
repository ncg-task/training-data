(Contribution||has||Experimental setup)
(Experimental setup||optimize||our loss)
(our loss||used||stochastic gradient descent)
(stochastic gradient descent||with||mini-batches)
(mini-batches||of size||32)
(Experimental setup||implemented||our models)
(our models||in||Torch library)
(Experimental setup||For||decoder)
(decoder||experimented with||Elman RNN)
(decoder||experimented with||Long - Short Term Memory ( LSTM ) architecture)
(Experimental setup||chose||hyper - parameters)
(hyper - parameters||based on||grid search)
(hyper - parameters||picked the one which gave||best perplexity)
(best perplexity||on||validation set)
(Experimental setup||has||final Elman architecture ( RAS - Elman ))
(final Elman architecture ( RAS - Elman )||uses||single layer)
(single layer||with||H = 512 , ? = 0.5 , ? = 2 , and ? = 10)
(Experimental setup||has||LSTM model ( RAS - LSTM ))
(LSTM model ( RAS - LSTM )||has||single layer)
(single layer||with||H = 512 , ? = 0.1 , ? = 2 , and ? = 10)
(Experimental setup||During||training)
(training||measure||perplexity)
(perplexity||of||summaries)
(summaries||in||validation set)
(training||adjust||hyper - parameters)
(hyper - parameters||such as||learning rate)

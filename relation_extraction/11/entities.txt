230	12	25	validate that
230	26	30	GCNs
230	35	56	effective at encoding
230	57	78	syntactic information
231	173	181	inducing
231	31	47	side information
231	199	207	leads to
231	208	236	improved relation extraction
240	17	22	model
240	23	31	performs
240	32	36	best
240	37	41	when
240	42	49	aliases
240	54	65	provided by
240	70	72	KB
241	23	29	RESIDE
241	30	35	gives
241	36	59	competitive performance
241	65	69	when
241	70	119	very limited amount of relation alias information
241	120	122	is
241	123	132	available
242	3	10	observe
242	16	27	performance
242	28	49	improves further with
242	54	92	availability of more alias information
198	0	5	Mintz
198	8	45	Multi-class logistic regression model
198	58	61	for
198	62	90	distant supervision paradigm
199	0	6	MultiR
199	9	38	Probabilistic graphical model
199	39	42	for
199	43	66	multi instance learning
199	70	76	MIMLRE
200	2	17	graphical model
200	24	38	jointly models
200	39	77	multiple instances and multiple labels
201	18	22	PCNN
201	27	62	CNN based relation extraction model
201	72	76	uses
201	77	100	piecewise max - pooling
201	101	104	for
201	105	128	sentence representation
202	0	10	PCNN + ATT
202	15	38	piecewise max - pooling
202	39	43	over
202	44	59	CNN based model
202	77	83	to get
202	84	107	sentence representation
202	108	119	followed by
202	120	144	attention over sentences
203	0	4	BGWA
203	7	47	Bi - GRU based relation extraction model
203	48	52	with
203	53	86	word and sentence level attention
45	70	110	http://github.com / malllabiisc / RESIDE
39	19	26	propose
39	27	33	RESIDE
39	38	89	novel distant supervised relation extraction method
39	96	104	utilizes
39	105	127	additional supervision
39	128	132	from
39	133	135	KB
39	136	143	through
39	148	181	neural network based architecture
40	0	6	RESIDE
40	7	12	makes
40	13	27	principled use
40	28	30	of
40	31	73	entity type and relation alias information
40	74	78	from
40	79	82	KBs
40	85	94	to impose
40	95	111	soft constraints
40	112	128	while predicting
40	133	141	relation
41	3	7	uses
41	8	37	encoded syntactic information
41	38	51	obtained from
41	52	86	Graph Convolution Networks ( GCN )
41	89	99	along with
41	100	125	embedded side information
41	128	138	to improve
41	139	165	neural relation extraction
2	19	68	Distantly - Supervised Neural Relation Extraction
4	0	49	Distantly - supervised Relation Extraction ( RE )
15	0	26	Relation Extraction ( RE )
6	0	2	RE
219	13	22	find that
219	23	29	RESIDE
219	30	38	achieves
219	39	55	higher precision
219	56	60	over
219	65	84	entire recall range
219	85	87	on
219	88	105	both the datasets
220	8	28	non-neural baselines
220	29	46	could not perform
220	47	51	well
221	0	6	RESIDE
221	7	18	outperforms
221	19	38	PCNN + ATT and BGWA
222	4	22	higher performance
222	23	25	of
222	26	45	BGWA and PCNN + ATT
222	46	50	over
222	51	55	PCNN
222	56	66	shows that
222	67	76	attention
222	77	85	helps in
222	86	107	distant supervised RE

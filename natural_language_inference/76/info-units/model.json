{
  "has" : {
    "Model" : {
      "proposing" : {
        "attentive neural network" : {
          "capable of" : {
            "reasoning" : {
              "over" : {
                "entailments" : {
                  "of" : {
                    "pairs" : {
                      "of" : "words and phrases"
                    }
                  },
                  "by processing" : {
                    "hypothesis" : {
                      "conditioned on" : "premise"
                    }
                  }
                }
              }
            },
            "from sentence" : "In contrast , we are proposing an attentive neural network that is capable of reasoning over entailments of pairs of words and phrases by processing the hypothesis conditioned on the premise ."
          }
        }
      },
      "present" : {
        "neural model" : {
          "based on" : "LSTMs",
          "reads" : {
            "two sentences" : {
              "in" : "one go"
            }
          }
        }
      },
      "extend" : {
        "neural word - by - word attention mechanism" : {
          "to encourage" : {
            "reasoning" : {
              "over" : {
                "entailments" : {
                  "of" : {
                    "pairs" : {
                      "of" : "words and phrases"
                    }
                  }
                }
              }
            }
          },
          "from sentence" : "Our contributions are threefold : ( i ) We present a neural model based on LSTMs that reads two sentences in one go to determine entailment , as opposed to mapping each sentence independently into a semantic space ( 2.2 ) , ( ii ) We extend this model with a neural word - by - word attention mechanism to encourage reasoning over entailments of pairs of words and phrases ( 2.4 ) , and ( iii ) We provide a detailed qualitative analysis of neural attention for RTE ( 4.1 ) ."
        }
      }
    }
  }
}
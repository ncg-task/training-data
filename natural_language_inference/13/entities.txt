153	0	4	RACE
153	11	26	key competitors
153	27	30	are
153	35	76	Stanford Attention Reader ( Stanford AR )
153	79	108	Gated Attention Reader ( GA )
153	115	146	Dynamic Fusion Networks ( DFN )
157	0	9	Search QA
157	16	40	main competitor baseline
157	41	43	is
157	48	60	AMANDA model
161	0	11	NarrativeQA
163	51	60	baselines
163	61	64	are
163	67	120	context - less sequence to sequence ( seq2seq ) model
163	123	126	ASR
163	131	136	BiDAF
176	3	12	implement
176	13	23	all models
176	24	26	in
176	27	37	TensorFlow
177	0	15	Word embeddings
177	20	36	initialized with
177	37	56	300d Glo Ve vectors
177	65	88	not fine - tuned during
177	89	97	training
178	0	12	Dropout rate
178	16	29	tuned amongst
178	30	49	{ 0.1 , 0.2 , 0.3 }
178	50	52	on
178	53	63	all layers
178	64	73	including
178	78	93	embedding layer
186	4	14	batch size
186	18	24	set to
186	25	34	64/256/32
187	4	28	maximum sequence lengths
187	29	32	are
187	33	45	500/200/1100
185	3	8	adopt
185	13	27	Adam optimizer
185	28	32	with
185	35	48	learning rate
185	49	51	of
185	52	71	0.0003/ 0.001/0.001
185	72	75	for
185	76	105	RACE / SearchQA / NarrativeQA
189	54	62	based on
189	65	76	TitanXP GPU
189	27	49	all runtime benchmarks
189	15	22	trained
189	0	10	All models
24	17	24	propose
24	27	52	new compositional encoder
24	72	90	used in - place of
24	91	112	standard RNN encoders
24	116	124	serve as
24	127	137	new module
24	146	162	complementary to
24	163	192	existing neural architectures
25	0	25	Our proposed MRU encoders
25	26	32	learns
25	33	47	gating vectors
25	48	51	via
25	52	91	multiple contract - and - expand layers
25	92	94	at
25	95	123	multiple dilated resolutions
28	4	30	k document representations
28	33	35	at
28	36	69	multiple ranges and n-gram blocks
28	81	106	combined and modeled with
28	107	129	fully connected layers
28	130	137	to form
28	142	166	final compositional gate
28	177	189	applied onto
28	194	217	original input document
26	18	26	compress
26	31	45	input document
26	49	113	arbitrary k times at multi-ranges ( e.g. , 1 , 2 , 4 , 10 , 25 )
26	114	118	into
26	121	170	neural bag - of - words ( summed ) representation
27	29	43	passed through
27	44	72	affine transformation layers
27	82	96	re-expanded to
27	101	125	original sequence length
2	26	47	Machine Comprehension
4	88	116	machine comprehension ( MC )
19	90	92	MC
194	21	23	on
194	24	28	RACE
190	21	36	6 % improvement
190	37	39	on
190	44	60	RACE - H dataset
190	65	82	1.8 % improvement
190	83	85	on
190	90	106	RACE - M dataset
195	112	129	Sim . MRU and MRU
195	134	141	achieve
195	142	164	comparable performance
195	165	167	to
195	168	178	each other
195	187	206	GRU and LSTM models
195	207	218	do not have
195	221	237	competitive edge
195	254	264	no encoder
195	273	281	achieves
195	282	306	comparable 1 performance
195	307	309	to
195	310	313	DFN
196	13	41	ensemble of Sim . MRU models
196	42	49	achieve
196	50	84	state - of - the - art performance
196	85	87	on
196	92	104	RACE dataset
196	107	116	achieving
196	121	135	over all score
196	136	138	of
196	139	145	53.3 %
198	55	77	Narrative QA benchmark
199	11	23	observe that
199	24	32	300d MRU
199	33	44	can achieve
199	45	67	comparable performance
199	68	72	with
199	73	78	BiDAF
200	5	18	compared with
200	21	27	BiLSTM
200	28	30	of
200	31	64	equal output dimensions ( 150 d )
200	70	79	find that
200	84	93	MRU model
200	94	102	performs
200	103	116	competitively
200	119	123	with
200	124	149	less than 1 % deprovement
200	150	156	across
200	157	168	all metrics
202	4	18	performance of
202	19	28	our model
202	29	31	is
202	32	52	significantly better
202	53	57	than
202	58	73	300d LSTM model
202	80	90	also being
202	91	111	significantly faster
206	14	24	MRU - LSTM
206	25	50	significantly outperforms
206	51	61	all models
206	64	73	including
206	74	79	BiDAF
207	0	23	Performance improvement
207	24	28	over
207	33	53	vanilla BiLSTM model
207	54	65	ranges from
207	66	75	1 % ? 3 %
207	76	82	across
207	83	94	all metrics

{
  "has" : {
    "Experiments" : {
      "has" : {
        "Tasks" : {
          "has" : {
            "Copying Memory Task" : {
              "has" : {
                "Hyperparameters" : {
                  "use" : {
                    "RMSProp optimization" : {
                      "with" : {
                        "learning rate" : {
                          "of" : "0.001"
                        },
                        "decay rate" : {
                          "of" : "0.9"
                        }
                      },
                      "from sentence" : "The first task we consider is the well known Copying Memory Task .
In this experiment , we use RMSProp optimization with a learning rate of 0.001 and a decay rate of 0.9 for all models ."

                    }
                  },
                  "has" : {
                    "batch size" : {
                      "set to" : "128",
                      "from sentence" : "The batch size is set to 128 ."
                    },
                    "Hidden state sizes" : {
                      "set to" : "128 , 100 , 90 , 512",
                      "to match" : {
                        "total number" : {
                          "of" : "hidden to hidden parameters"
                        }
                      },
                      "from sentence" : "Hidden state sizes are set to 128 , 100 , 90 , 512 , respectively to match total number of hidden to hidden parameters ."
                    }
                  }
                },
                "Results" : {
                  "has" : {
                    "GORU" : {
                      "is" : "only gated - system",
                      "to" : {
                        "successfully solve" : {
                          "has" : "task"
                        }
                      },
                      "from sentence" : "The GORU is the only gated - system to successfully solve this task while the GRU and LSTM get stuck at the baseline as shown in ."
                    }
                  }
                }
              }
            },
            "Denoise Task" : {
              "has" : {
                "Hyperparameters" : {
                  "use" : {
                    "RM - SProp optimization algorithm" : {
                      "with" : {
                        "learning rate" : {
                          "of" : "0.01"
                        },
                        "decay rate" : {
                          "of" : "0.9"
                        }
                      },
                      "from sentence" : "Denoise Task
Just as in the previous experiment , we use RM - SProp optimization algorithm with a learning rate of 0.01 and a decay rate of 0.9 for all models ."

                    }
                  },
                  "has" : {
                    "batch size" : {
                      "set to" : "128",
                      "from sentence" : "The batch size is set to 128 ."
                    },
                    "Hidden state sizes" : {
                      "set to" : {
                        "128 , 100 , 90 , 512" : {
                          "to match" : "total number of hidden to hidden parameters"
                        }
                      },
                      "from sentence" : "Hidden state sizes are set to 128 , 100 , 90 , 512 , respectively to match total number of hidden to hidden parameters ."
                    }
                  }
                },
                "Results" : {
                  "has" : {
                    "GORU and GRU" : {
                      "has" : {
                        "successfully solve" : {
                          "has" : "task"
                        }
                      },
                      "from sentence" : "EURNN get stuck at the baseline because of lacking forgetting mechanism , while GORU and GRU successfully solve the task ."
                    }
                  }
                }
              }
            },
            "Parenthesis Task" : {
              "has" : {
                "Hyperparameters" : {
                  "has" : {
                    "total input length" : {
                      "set to" : "200",
                      "from sentence" : "Parenthesis Task
In our experiment , the total input length is set to 200 ."

                    }
                  },
                  "used" : {
                    "batch size" : {
                      "has" : "128"
                    },
                    "RMSProp Optimizer" : {
                      "with" : {
                        "learning rate" : {
                          "has" : "0.001"
                        },
                        "decay rate" : {
                          "has" : "0.9"
                        }
                      }
                    },
                    "from sentence" : "We used batch size 128 and RMSProp Optimizer with a learning rate 0.001 , decay rate 0.9 on all models ."
                  }
                },
                "Results" : {
                  "has" : {
                    "GORU" : {
                      "able to" : {
                        "successfully outperform" : {
                          "has" : ["GRU", "LSTM", "EURNN"],
                          "in terms of" : ["learning speed", "final performances"],
                          "from sentence" : "The GORU is able to successfully outperform GRU , LSTM and EURNN in terms of both learning speed and final performances as shown in ."
                        }
                      }
                    }
                  },
                  "analyzed" : {
                    "update gates" : {
                      "for" : "GORU and GRU",
                      "from sentence" : "We also analyzed the activations of the update gates for GORU and GRU ."
                    }
                  }
                }
              }
            },
            "Algorithmic Task" : {
              "has" : {
                "Hyperparameters" : {
                  "used" : {
                    "batch size" : {
                      "has" : "50"
                    },
                    "hidden size" : {
                      "has" : "128"
                    },
                    "from sentence" : "Algorithmic Task
We used batch size 50 and hidden size 128 for all models ."
                  },
                  "has" : {
                    "RNNs" : {
                      "trained with" : {
                        "RMSProp optimizer" : {
                          "with" : {
                            "learning rate" : {
                              "of" : "0.001"
                            },
                            "decay rate" : {
                              "of" : "0.9"
                            }
                          }
                        },
                        "from sentence" : "The RNNs are trained with RMSProp optimizer with a learning rate of 0.001 and decay rate of 0.9 ."
                      }
                    }
                  }
                },
                "Results" : {
                  "found that" : {
                    "GORU" : {
                      "performs" : {
                        "averagely better" : {
                          "than" : "GRU / LSTM and EURNN"
                        }
                      }
                      "from sentence" : "We found that the GORU performs averagely better than GRU / LSTM and EURNN ."
                    }
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
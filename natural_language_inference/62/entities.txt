198	37	46	replacing
198	51	87	knowledge aided attention mechanisms
198	88	92	with
198	97	113	mutual attention
198	134	148	self attention
198	178	187	find that
198	192	201	F 1 score
198	202	204	of
198	205	208	KAR
198	209	217	drops by
198	218	221	4.2
198	222	224	on
198	229	244	development set
198	247	250	7.8
198	251	253	on
198	254	261	AddSent
198	268	271	9.1
198	272	274	on
198	275	285	AddOneSent
41	21	28	propose
41	31	53	data enrichment method
41	56	66	which uses
41	67	74	WordNet
41	75	85	to extract
41	86	117	inter-word semantic connections
41	118	120	as
41	121	138	general knowledge
41	139	143	from
41	144	178	each given passage - question pair
42	34	58	end - to - end MRC model
42	59	64	named
42	68	98	Knowledge Aided Reader ( KAR )
42	107	122	explicitly uses
42	133	160	extracted general knowledge
42	161	170	to assist
42	175	195	attention mechanisms
181	3	11	tokenize
181	16	27	MRC dataset
181	28	32	with
181	33	46	spa Cy 2.0.13
181	49	59	manipulate
181	60	71	WordNet 3.0
181	72	76	with
181	77	85	NLTK 3.3
181	92	101	implement
181	102	105	KAR
181	106	110	with
181	111	128	TensorFlow 1.11.0
183	0	3	For
183	8	36	dense layers and the BiLSTMs
183	42	45	set
183	50	71	dimensionality unit d
183	72	74	to
183	75	78	600
184	4	22	model optimization
184	28	33	apply
184	38	77	Adam ( Kingma and Ba , 2014 ) optimizer
184	78	82	with
184	85	98	learning rate
184	99	101	of
184	102	108	0.0005
184	115	129	minibatch size
184	130	132	of
184	133	135	32
186	0	8	To avoid
186	9	20	overfitting
186	26	31	apply
186	32	39	dropout
186	40	42	to
186	47	59	dense layers
186	68	75	BiLSTMs
186	76	80	with
186	83	95	dropout rate
186	96	98	of
186	99	102	0.3
187	0	8	To boost
187	13	24	performance
187	30	35	apply
187	36	62	exponential moving average
187	63	67	with
187	70	80	decay rate
187	81	83	of
187	84	89	0.999
2	45	74	Machine Reading Comprehension
4	26	63	Machine Reading Comprehension ( MRC )
4	236	239	MRC
199	56	59	KAR
199	116	118	on
199	123	138	development set
199	68	76	achieves
199	80	82	EM
199	42	44	of
199	86	90	71.9
199	98	107	F 1 score
199	83	85	of
199	111	115	80.8
199	150	161	even better
199	162	166	than
199	171	188	final performance
199	108	110	of
199	192	216	several strong baselines
199	219	226	such as
199	227	256	DCN ( EM / F1 : 65.4 / 75.6 )
199	261	292	BiDAF ( EM / F1 : 67.7 / 77.3 )

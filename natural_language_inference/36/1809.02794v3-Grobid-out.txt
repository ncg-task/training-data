title
Explicit Contextual Semantics for Text Comprehension
abstract
Who did what to whom is a major focus in natural language understanding, which is right the aim of semantic role labeling (SRL) task. Despite of sharing a lot of processing characteristics and even task purpose, it is surprisingly that jointly considering these two related tasks was never formally reported in previous work. Thus this paper makes the first attempt to let SRL enhance text comprehension and inference through specifying verbal predicates and their corresponding semantic roles. In terms of deep learning models, our embeddings are enhanced by explicit contextual semantic role labels for more fine-grained semantics. We show that the salient labels can be conveniently added to existing models and significantly improve deep learning models in challenging text comprehension tasks. Extensive experiments on benchmark machine reading comprehension and inference datasets verify that the proposed semantic learning helps our system reach new state-of-the-art over strong baselines which have been enhanced by well pretrained language models from the latest progress.
Introduction
Text comprehension is challenging for it requires computers to read and understand natural language texts to answer questions or make inference, which is indispensable for advanced context-oriented dialogue and interactive systems. This paper focuses on two core text comprehension (TC) tasks, machine reading comprehension (MRC) and textual entailment (TE).
One of the intrinsic challenges for text comprehension is semantic learning. Though deep learning has been applied to natural language processing (NLP) tasks with remarkable performance, recent studies have found deep learning models might not really understand the natural language texts and vulnerably suffer from adversarial attacks. Typically, an MRC model pays great attention to non-significant words and ignores important ones. To help model better understand natural language, we are motivated to discover an effective way to distill semantics inside the input sentence explicitly, such as semantic role labeling, instead of completely relying on uncontrollable model parameter learning or manual pruning.
Semantic role labeling (SRL) is a shallow semantic parsing task aiming to discover who did what to whom, when and why, providing explicit contextual semantics, which naturally matches the task target of text comprehension. For MRC, questions are usually formed with who, what, how, when and why, whose predicate-argument relationship that is supposed to be from SRL is of the same importance as well. Be- sides, explicit semantics has been proved to be beneficial to a wide range of NLP tasks, including discourse relation sense classification, machine translation and question answering. All the previous successful work indicates that explicit contextual semantics may hopefully help into reading comprehension and inference tasks. Some work studied question answering (QA) driven SRL, like QA-SRL parsing. They focus on detecting argument spans for a predicate and generating questions to annotate the semantic relationship. However, our task is quite different. In QA-SRL, the focus is commonly simple and short factoid questions thatare less related to the context, let alone making inference. Actually, text comprehension and inference are quite challenging tasks in NLP, requiring to dig the deep semantics between the document and comprehensive question which are usually raised or re-written by humans, instead of shallow argument alignment around the same predicate in QA-SRL. In this work, to alleviate such an obvious shortcoming about semantics, we make attempt to explore integrative models for finer-grained text comprehension and inference.
In this work, we propose a semantics enhancement framework for TC tasks, which boosts the strong baselines effectively. We implement an easy and feasible scheme to integrate semantic signals in downstream neural models in end-to-end manner to boost strong baselines effectively. An example about how contextual semantics helps MRC is illustrated in. A series of detailed case studies are employed to analyze the robustness of the semantic role labeler. To our best knowledge, our work is the first attempt to apply explicit contextual semantics for text comprehension tasks, which have been ignored in previous works for a longtime.
The rest of this paper is organized as follows. The next section reviews the related work. Section 3 will demonstrate our semantic learning framework and implementation. Task details and experimental results are reported in Section 4, followed by case studies and analysis in Section 5 and conclusion in Section 6.

Related Work

Text Comprehension
As a challenging task in NLP, text comprehension is one of the key problems in artificial intelligence, which aims to read and comprehend a given text, and then answer questions or make inference based on it. These tasks require a comprehensive understanding of natural languages and the ability to do further inference and reasoning. We focus on two types of text comprehension, document-based questionanswering) and textual entailment (. Textual entailment aims for a deep understanding of text and reasoning, which shares the similar genre of machine reading comprehension, though the task formations are slightly different.
In the last decade, the MRC tasks have evolved from the early cloze-style test to spanbased answer extraction from passage. The former has restrictions that each answer should be a single word in the document and the original sentence without the answer part is taken as the query. For the span-based one, the query is formed as questions in natural language whose answers are spans of texts. Various attentive models have been employed for text representation and relation discovery, including Attention Sum Reader, Gated attention Reader and Self-matching Network Passage There are three major types of rock: igneous, sedimentary, and metamorphic. The rock cycle is an important concept in geology which illustrates the relationships between these three types of rock, and magma. When a rock crystallizes from melt (magma and/or lava), it is an igneous rock. This rock can be weathered and eroded, and then redeposited and lithified into a sedimentary rock, or be turned into a metamorphic rock due to heat and pressure that change the mineral content of the rock which gives it a characteristic fabric. The sedimentary rock can then be subsequently turned into a metamorphic rock due to heat and pressure and is then weathered, eroded, deposited, and lithified, ultimately becoming a sedimentary rock. Sedimentary rock may also be re-eroded and redeposited, and metamorphic rock may also undergo additional metamorphism. All three types of rocks maybe re-melted; when this happens, a new magma is formed, from which an igneous rock may once again crystallize. Question What changes the mineral content of a rock? Answer heat and pressure. Hypo.
The man is competing in a competition. Neutral The man parasailed in the calm water.
Contra. The water was choppy as the man parasailed. Entailment.
With the release of the large-scale span-based datasets, which constrain answers to all possible text spans within the reference document, researchers are investigating the models with more logical reasoning and content understanding . Recently, language models also show their remarkable performance in reading comprehension.
For the other type of text comprehension, natural language inference (NLI) is proposed to serve as a benchmark for natural language understanding and inference, which is also known as recognizing textual entailment (RTE). In this task, a model is presented with a pair of sentences and asked to judge the relationship between their meanings, including entailment, neutral and contradiction. Bowman et al. released Stanford Natural language Inference (SNLI) dataset, which is a high-quality and largescale benchmark, thus inspiring various significant work.
Most of existing NLI models apply attention mechanism to jointly interpret and align the premise and hypothesis, while transfer learning from external knowledge is popular recently. Notably, proposed an enhanced sequential inference model (ESIM), which employed recursive architectures in both local inference modeling and inference composition, as well as syntactic parsing information, for a sequential inference model. ESIM is simple with satisfactory performance, and thus is widely chosen as the baseline model. proposed to transfer the LSTM encoder from the neural machine translation (NMT) to the NLI task to contextualize word vectors. transferred the knowledge learned from the discourse marker prediction task to the NLI task to augment the semantic representation.

Semantic Role Labeling
Given a sentence, the task of semantic role labeling is dedicated to recognizing the semantic relations between the predicates and the arguments. For example, given the sentence, Charlie sold a book to Sherry last week, where the target verb (predicate) is sold, SRL system yields the following outputs,
where ARG0 represents the seller (agent), ARG1 represents the thing sold (theme), ARG2 represents the buyer (recipient), AM ? TM P is an adjunct indicating the timing of the action and V represents the predicate.
Recently, SRL has aroused much attention from researchers and has been applied in many NLP tasks. SRL task is generally formulated as multi-step classification subtasks in pipeline systems, consisting of predicate identification, predicate dis ambiguation, argument identification and argument classification. Most previous SRL approaches adopt a pipeline framework to handle these subtasks one after another. Notably, devised the first automatic semantic role labeling system based on FrameNet. Traditional systems relied on sophisticated handcraft features or some declarative constraints, which suffer from poor efficiency and generalization ability. A recently ten-dency for SRL is adopting neural networks methods thanks to their significant success in a wide range of applications. The pioneering work on building an end-to-end neural system was presented by, applying an 8 layered LSTM model, which takes only original text information as input feature without using any syntactic knowledge, outperforming the previous state-of-the-art system. presented a deep highway BiLSTM architecture with constrained decoding, which is simple and effective, enabling us to select it as our basic semantic role labeler. These studies tackle argument identification and argument classification in one shot. Inspired by recent advances, we can easily integrate semantics into text comprehension.

Semantic Role Labeling for Text Comprehension
For both downstream text comprehension tasks, we consider an end-to-end model as well as the semantic learning model. The former maybe regarded as downstream model of the latter. Thus, our semantics augmented model will bean integration of two end-to-end models through simple embedding concatenation as shown in.
In detail, we apply semantic role labeler to annotate the semantic tags (i.e. predicate, argument) for each token in the input sequence so that explicit contextual semantics can be directly introduced, and then the input sequence along with the corresponding semantic role labels is fed to downstream models. We regard the semantic signals as SRL embeddings and employ a lookup table to map each label to vectors, similar to the implementation of word embedding. For each word x, a joint embedding e j (w) is obtained by the concatenation of word embedding e w (x) and SRL embedding e s (x),
where ? is the concatenation operator. The downstream model is task-specific. In this work, we focus on the textual entailment and machine reading comprehension, which will be discussed latter.

Semantic Role Labeler

Downstream Model
Word embedding SRL embedding While the CoNLL-2005 shared task assumes gold predicates as input, this information is not available in many applications, which requires us to identify the predicates for a input sentence at the very beginning. Thus, our SRL module has to be end-toend, predicting all predicates and corresponding arguments in one shot.
For predicate identification, we use spaCy 1 to tokenize the input sentence with part-of-speech (POS) tags and the verbs are marked as the binary predicate indicator for whether the word is the verb for the sentence.
Following, we model SRL as a span tagging problem 2 and use an 8-layer deep BiL-STM with forward and backward directions interleaved. Different from the baseline model, we replace the GloVe embeddings with ELMo representations 3 due to the recent success of ELMo in NLP tasks.
In brief, the implementation of our SRL is a series of stacked interleaved LSTMs with highway connections. The inputs are embedded sequences of words concatenated with a binary indicator containing whether a word is the verbal predicate. Additionally, during inference, Viterbi decoding is applied to accommodate valid BIO sequences. The details are 1 https://spacy.io/ 2 Actually, the easiest way to deal with segmentation or sequence labeling problems is to transform them into raw labeling problems. A standard way to do this is the BIO encoding, representing a token at the beginning, interior, or outside of any span, respectively.
3 The ELMo representation is obtained from https:// allennlp.org/elmo. We use the original one for this work whose output size is 512. as follows.
Word Representation The word representation of our SRL model is the concatenation of two vectors: an ELMo embedding e (l) and predicate indicator embedding (PIE) e (p) . ELMo is trained from the internal states of a deep bidirectional language model (BiLM), which is pre-trained on a large text corpus with approximately 30 million sentences. Besides, following  who shows the predicate-specific feature is helpful in promoting the role labeling, we employ a predicate indicator embedding e (p) to mark whether a word is a predicate when predicting and labeling the arguments. The final word representation is given bye = e (l) ? e (p) , where ? is the concatenation operator. The downstream model will take such a joint embedding as input for specific task.
Encoder As commonly used to model the sequential input, BiLSTM is adopted for our sentence encoder. By incorporating a stack of distinct LSTMs, BiLSTM processes an input sequence in both forward and backward directions. In this way, the BiL-STM encoder provides the ability to incorporate the contextual information for each word. Given a sequence of word representation S = {e 1 , e 2 , ? ? ? , en } as input, the hidden state h = {h 1 , h 2 , ? ? ? , h n } is encoded by BiLSTMs layer where each LSTM uses highway connections between layers and variational recurrent dropout. The encoded representation is then projected using a final dense layer followed by a softmax activation to form a distribution over all possible tags. The predicted semantic role Labels are defined in PropBank augmented with B-I-O tag set to represent argument spans.
Model Implementation The training objective is to maximize the logarithm of the likelihood of the tag sequence, and we expect the correct output sequence matches with,
where C is candidate label set. Our semantic role labeler is trained on English OntoNotes v5.0 dataset for the CoNLL-2012 shared task, achieving an F1 of 84.6% 4 on the test set. At test time, we perform Viterbi decoding to enforce valid spans using BIO constraints 5 . For the following evaluation, the default dimension of SRL embeddings is 5 and the case study concerning the dimension is shown in the subsection dimension of SRL Embedding.
The model is run forward for every verb in the sentence. In some cases there is more than one predicate in a sentence, resulting in various semantic role sets whose number is equal to the number of predicates. For convenient downstream model input, we need to ensure the word and the corresponding label are matched one-by-one, that is, only one set for a sentence. To this end, we select the corresponding BIO sets with the most non-O labels as the semantic role labels. For sentences with no predicate, we directly assign O labels to each word in those sentences.

Text Comprehension Model
Textual Entailment Our basic TE model is the reproduced Enhanced Sequential Inference Model (ESIM) which is a widely used baseline model for textual entailment. ESIM employs a BiLSTM to encode the premise and hypothesis, followed by an attention layer, a local inference layer, an inference composition layer. Slightly different from, we do not include extra syntactic parsing features and directly replace the pre-trained Glove word embedding with ELMo which are completely character based. Our SRL embedding is concatenated with ELMo embeddings and the joint embeddings are then fed to the BiL-STM encoders.

Machine Reading Comprehension Our baseline MRC model is an enhanced version of Bidirectional
Attention Flow following . The token embedding is the concatenation of pre-trained GloVe word vectors, a character-level embedding from a convolutional neural network with max-pooling and pre-trained ELMo embeddings. Our semantics enhanced model takes input of concatenating the token embedding with SRL embeddings. The embeddings of document and question are passed through a shared bi-directional GRU, followed by a BiDAF attention. The contextual document and question representations are then passed to a residual self-attention layer. The above model is denoted as ELMo. shows the results on SQuAD MRC task 6 . The SRL embeddings give substantial performance gains over all the strong baselines, showing it is also quite effective for more complex document and question encoding.

Model
Accuracy

Evaluation
In this section, we evaluate the performance of SRL embeddings on two kinds of text comprehension tasks, textual entailment and reading comprehension. Both of the concerned tasks are quite challenging, and could be even more difficult considering that the latest performance improvement has been already very marginal. However, we present the semantics enhanced solution instead of heuristically stacking network design techniques to give further advances. In our experiments, we basically  follow the same hyper-parameters for each model as the original settings from their corresponding literatures except those specified (e.g. SRL embedding dimension). For both of the tasks, we also report the results by using pre-trained BERT as word representation in our baseline models 7 . The hyperparameters were selected using the Dev set, and the reported Dev and Test scores are averaged over 5 random seeds using those hyper-parameters.

Textual Entailment
Textual entailment is the task of determining whether a hypothesis is entailment, contradiction and neutral, given a premise. The Stanford Natural Language Inference (SNLI) corpus provides approximately 570k hypothesis/premise pairs. We evaluate the model performance in terms of accuracy.
Results in show that SRL embedding can boost the ESIM+ELMo model by +0.7% improvement. With the semantic cues, the simple sequential encoding model yields substantial gains, and our single BERT LARGE model also achieves a new stateof-the-art, even outperforms all the ensemble models in the leaderboard 8 . This would be owing to more accurate and fine-grained information from effective explicit semantic cues.
To evaluate the contributions of key factors in our method, a series of ablation studies are performed on the SNLI dev and test set. The results are in. We observe both SRL and ELMo embeddings contribute to the over all performance. Note that ELMo is obtained by deep bidirectional language with 4,096 hidden units on a large-scale corpus, which requires long training time with 93.6 million parameters. The output dimension of ELMo is 512. Compared with the massive computation and high dimension, SRL embedding is much more convenient for training and much easier for model integration, giving the same level of performance gains.

Machine Reading Comprehension
To investigate the effectiveness of the SRL embedding in conjunction with more complex models, we conduct experiments on machine reading comprehension tasks. The reading comprehension task can be described as a triple < D, Q, A >, where Dis a document (context), Q is a query over the contents of D, in which a span is the right answer A.
As a widely used benchmark dataset for machine reading comprehension, the Stanford Question Answering Dataset (SQuAD) contains 100k+ crowd sourced questionanswer pairs where the answer is a span in a given Wikipedia paragraph. Two official metrics are selected to evaluate the model performance: Exact Match (EM) and a softer metric F1 score, which measures the weighted average of the precision and recall rate at a character level. Our baseline includes MQAN for single task and multi-task with SRL, BiDAF+ELMo, R.M. Reader and BERT. shows the results 9 . The SRL embeddings give substantial performance gains over all the strong baselines, showing it is also quite effective for more complex document and question encoding.

Case Studies
From the above experiments, we see our semantic learning framework works effectively and the semantic role labeler boosts model performance, verifying our hypothesis that semantic roles are critical for text understanding. Though the semantic role labeler is trained on a standard benchmark dataset,  Ontonotes, whose source ranges from news, conversational telephone speech, weblogs, etc., it turns out to be generally useful for text comprehension from probably quite different domains in both textual entailment and machine reading comprehension. To further evaluate the proposed method, we conduct several case studies as follows.

Dimension of SRL Embedding
The dimension of embedding is a critical hyperparameter in deep learning models that may influence the performance.  cause severe over-fitting issues while too low dimension would also cause under-fitting results. To investigate the influence of the dimension of SRL embeddings, we change the dimension in the intervals. shows the results. We see that 5-dimension SRL embedding gives the best performance on both SNLI and SQuAD datasets.

Comparison with POS/NER Tags
The study of computational linguistics is a critical part in NLP.
In particular, Part-of-speech (POS) and named entity (NE) tags have been broadly used in various tasks.
To make comparisons, we conduct experiments on SNLI with modifications on label embeddings using tags of SRL, POS and NE, respectively. Results in show that SRL gives the best result, showing semantic roles contribute to the performance, which also indicates that semantic information matches the purpose of NLI task best.

Conclusion
This paper presents a novel semantic learning framework for fine-grained text comprehension and inference. We show that our proposed method is simple yet powerful, which achieves a significant improvement over strong baseline models, including those which have been enhanced by the latest BERT. This work discloses the effectiveness of explicit semantics in text comprehension and inference and proposes an easy and feasible scheme to integrate explicit contextual semantics in neural models. A series of detailed case studies are employed to analyze the adopted robustness of the semantic role labeler. Different from most recent works focusing on heuristically stacking complex mechanisms for performance improvement, this work is to shed some lights on fusing accurate semantic signals for deeper comprehension and inference.
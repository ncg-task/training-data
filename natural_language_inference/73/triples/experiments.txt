(Contribution||has||Experiments)
(Experiments||has||Tasks)
(Tasks||has||Natural Language Inference)
(Natural Language Inference||has||Results)
(Results||Compared to||convolutional models)
(convolutional models||has||ReSAN)
(ReSAN||has||significantly outperforms)
(significantly outperforms||by||3.1 % and 2.4 %)
(convolutional models||i.e.||Multiwindow CNN)
(convolutional models||i.e.||Hierarchical CNN)
(Results||Compared to||recurrent models)
(recurrent models||due to||parallelizable computations)
(parallelizable computations||has||ReSAN)
(ReSAN||shows||better prediction quality)
(ReSAN||shows||more compelling efficiency)
(recurrent models||e.g.||Bi - LSTM)
(recurrent models||e.g.||Bi - GRU)
(Results||Compared to||attention - based models)
(attention - based models||name||multi-head attention)
(attention - based models||name||DiSAN)
(attention - based models||has||ReSAN)
(ReSAN||with||better test performance)
(ReSAN||with||less time cost)
(ReSAN||uses||similar number of parameters)
(Results||has||ReSAN)
(ReSAN||has||outperforms)
(outperforms||has||300D SPINN - PI encoders)
(300D SPINN - PI encoders||by||3.1 %)
(Results||compared to||last best models)
(last best models||has||ReSAN)
(ReSAN||with||better performance)
(ReSAN||uses||far fewer parameters)
(last best models||i.e.||600D Gumbel TreeLSTM encoders)
(last best models||i.e.||600D Residual stacked encoders)

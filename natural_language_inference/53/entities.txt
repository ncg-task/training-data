15	19	24	study
15	29	33	task
15	34	36	of
15	37	45	learning
15	46	84	universal representations of sentences
15	96	118	sentence encoder model
15	127	137	trained on
15	140	152	large corpus
15	157	184	subsequently transferred to
15	185	196	other tasks
18	10	21	investigate
18	30	49	supervised learning
18	50	56	can be
18	57	66	leveraged
22	27	33	impact
22	34	36	of
22	41	71	sentence encoding architecture
22	72	74	on
22	75	107	representational transferability
22	114	121	compare
22	122	189	convolutional , recurrent and even simpler word composition schemes
88	0	3	For
88	12	18	models
88	19	29	trained on
88	30	34	SNLI
88	40	43	use
88	44	47	SGD
88	48	52	with
88	55	68	learning rate
88	69	71	of
88	72	75	0.1
88	82	94	weight decay
88	95	97	of
88	98	102	0.99
91	8	18	classifier
91	24	27	use
91	30	54	multi - layer perceptron
91	55	59	with
91	60	76	1 hidden - layer
91	77	79	of
91	80	96	512 hidden units
89	0	2	At
89	3	13	each epoch
89	19	25	divide
89	30	43	learning rate
89	44	46	by
89	47	48	5
89	49	51	if
89	56	68	dev accuracy
89	69	78	decreases
90	3	6	use
90	7	18	minibatches
90	19	26	of size
90	27	29	64
90	34	42	training
90	43	45	is
90	46	53	stopped
90	54	58	when
90	63	76	learning rate
90	77	87	goes under
90	92	110	threshold of 10 ?5
92	7	31	opensource GloVe vectors
92	32	42	trained on
92	43	60	Common Crawl 840B
92	61	65	with
92	66	80	300 dimensions
92	81	83	as
92	84	105	fixed word embeddings
2	0	57	Supervised Learning of Universal Sentence Representations
141	0	19	Architecture impact
144	4	17	BiLSTM - 4096
144	18	22	with
144	27	50	max - pooling operation
144	51	59	performs
144	60	64	best
144	65	67	on
144	73	96	SNLI and transfer tasks
145	0	10	Looking at
145	15	39	micro and macro averages
145	57	65	performs
145	66	86	significantly better
145	87	91	than
145	96	108	other models
145	109	113	LSTM
145	116	119	GRU
145	122	134	BiGRU - last
145	137	150	BiLSTM - Mean
145	153	168	inner-attention
145	177	199	hierarchical - ConvNet
150	24	40	transfer quality
150	49	61	sensitive to
150	66	88	optimization algorithm
150	91	109	when training with
150	110	114	Adam
150	115	125	instead of
150	126	129	SGD
150	135	143	observed
150	153	165	BiLSTM - max
150	166	175	converged
150	176	182	faster
150	183	185	on
150	186	190	SNLI
150	224	232	obtained
150	233	246	worse results
150	247	249	on
150	254	268	transfer tasks
152	0	14	Embedding size
153	124	149	increased embedding sizes
153	150	157	lead to
153	158	179	increased performance
153	180	183	for
153	184	201	almost all models
170	0	27	Comparison with SkipThought
172	0	4	With
172	5	55	much less data ( 570 k compared to 64M sentences )
172	60	64	with
172	65	91	high - quality supervision
172	92	96	from
172	101	113	SNLI dataset
172	123	130	able to
172	131	154	consistently outperform
172	159	166	results
172	167	178	obtained by
172	179	198	SkipThought vectors
174	0	16	Our BiLSTM - max
174	17	27	trained on
174	28	32	SNLI
174	33	41	performs
174	42	53	much better
174	54	58	than
174	59	87	released SkipThought vectors
174	88	90	on
174	91	93	MR
174	96	98	CR
174	101	105	MPQA
174	108	111	SST
174	114	129	MRPC - accuracy
174	132	140	SICK - R
174	143	151	SICK - E
174	156	159	STS
175	38	46	performs
175	47	53	better
175	54	58	than
175	59	70	SkipThought
175	76	78	on
175	79	81	MR
175	84	86	CR
175	91	95	MPQA
175	0	10	Except for
175	15	27	SUBJ dataset
176	19	29	looking at
176	34	47	STS14 results
176	8	15	observe
176	57	71	cosine metrics
176	72	74	in
176	75	94	our embedding space
176	95	97	is
176	103	132	more semantically informative
176	133	137	than
176	141	168	SkipThought embedding space
178	0	32	NLI as a supervised training set
179	13	21	indicate
179	27	36	our model
179	37	47	trained on
179	48	52	SNLI
179	53	60	obtains
179	61	89	much better over all results
179	90	94	than
179	95	101	models
179	102	112	trained on
179	113	135	other supervised tasks
179	136	143	such as
179	144	148	COCO
179	151	173	dictionary definitions
179	176	179	NMT
179	182	186	PPDB
179	191	194	SST
183	0	31	Domain adaptation on SICK tasks
184	0	30	Our transfer learning approach
184	31	38	obtains
184	39	53	better results
184	54	58	than
184	59	90	previous state - of - the - art
186	8	34	significantly outperformed
186	35	72	previous transfer learning approaches
186	73	75	on
186	76	84	SICK - E
186	110	119	that used
186	124	134	parameters
186	135	137	of
186	141	151	LSTM model
186	152	162	trained on
186	163	167	SNLI
186	168	185	to fine - tune on
186	186	190	SICK
185	3	9	obtain
185	12	25	pearson score
185	26	28	of
185	29	34	0.885
185	35	37	on
185	38	46	SICK - R
185	84	104	86.3 % test accuracy
185	105	107	on
185	108	116	SICK - E
185	47	52	while
185	123	158	previous best handengineered models
185	53	61	obtained
185	168	174	84.5 %
188	0	33	Image - caption retrieval results
191	5	17	trained with
191	18	61	ResNet features and 30 k more training data
191	68	87	SkipThought vectors
191	88	95	perform
191	96	116	significantly better
191	117	121	than
191	126	142	original setting
191	145	155	going from
191	156	168	33.8 to 37.9
191	169	172	for
191	173	194	caption retrieval R@1
191	201	205	from
191	206	218	25.9 to 30.6
191	219	221	on
191	222	241	image retrieval R@1
192	0	12	Our approach
192	13	19	pushes
192	24	31	results
192	32	44	even further
192	47	51	from
192	52	56	37.9
192	57	59	to
192	60	64	42.4
192	65	67	on
192	68	86	cap-tion retrieval
192	93	97	30.6
192	98	100	to
192	101	105	33.2
192	106	108	on
192	109	124	image retrieval
195	0	14	MultiGenre NLI
199	3	10	observe
199	13	30	significant boost
199	31	33	in
199	34	54	performance over all
199	55	66	compared to
199	71	76	model
199	77	92	trained only on
199	93	97	SLNI
200	0	9	Our model
200	15	22	reaches
200	23	42	AdaSent performance
200	43	45	on
200	46	48	CR

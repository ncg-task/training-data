(Contribution||has||Experimental setup)
(Experimental setup||set||initial learning rate)
(initial learning rate||with||warm - up rate)
(warm - up rate||of||0.1)
(initial learning rate||with||L2 weight decay)
(L2 weight decay||of||0.01)
(initial learning rate||in||{ 8e -6 , 1 e - 5 , 2 e - 5 , 3 e - 5 })
(Experimental setup||use||pre-trained weights)
(pre-trained weights||of||BERT)
(Experimental setup||has||maximum number of epochs)
(maximum number of epochs||set in||[ 2 , 5 ])
(maximum number of epochs||depending on||tasks)
(Experimental setup||has||default maximum number)
(default maximum number||of||predicateargument structures m)
(predicateargument structures m||set to||3)
(Experimental setup||has||Our implementation)
(Our implementation||based on||PyTorch implementation)
(PyTorch implementation||of||BERT)
(Experimental setup||has||Texts)
(Texts||with||maximum length)
(maximum length||of||128 or 200)
(128 or 200||for||other tasks)
(maximum length||of||384)
(384||for||SQuAD)
(Texts||tokenized using||wordpieces)
(Experimental setup||has||batch size)
(batch size||selected in||{ 16 , 24 , 32 })
(Experimental setup||has||dimension)
(dimension||of||SRL embedding)
(SRL embedding||set to||10)
(Experimental setup||follow||same fine - tuning procedure)
(same fine - tuning procedure||as||BERT)
(BERT||has||all the layers)
(all the layers||tuned with||moderate model size)
(moderate model size||as||extra SRL embedding volume)
(extra SRL embedding volume||is||less than 15 %)
(less than 15 %||of||original encoder size)
(moderate model size||has||increasing)

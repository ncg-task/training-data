(Contribution||has||Baselines)
(Baselines||has||CNN)
(CNN||identical to||our textual feature extractor network)
(CNN||does not use||contextual information)
(Baselines||has||c- LSTM+ Att)
(c- LSTM+ Att||has||variant attention)
(variant attention||at||each timestamp)
(variant attention||applied to||c - LSTM output)
(Baselines||has||MFN)
(MFN||Specific to||multimodal scenario)
(MFN||utilizes||multi-view learning)
(multi-view learning||by modeling||view - specific and cross - view interactions)
(Baselines||has||CMN)
(CMN||has||state - of - the - art method)
(state - of - the - art method||models||utterance context)
(utterance context||from||dialogue history)
(dialogue history||using||two distinct GRUs)
(two distinct GRUs||for||two speakers)
(Baselines||has||c - LSTM)
(c - LSTM||is||Biredectional LSTM)
(Biredectional LSTM||used to capture||context)
(context||from||surrounding utterances)
(surrounding utterances||to generate||contextaware utterance representation)
(Baselines||has||TFN)
(TFN||specific to||multimodal scenario)
(TFN||has||Tensor outer product)
(Tensor outer product||used to capture||intermodality and intra-modality interactions)
(Baselines||has||Memnet)
(Memnet||has||output)
(output||from||memory network)
(memory network||used as||final utterance representation)
(final utterance representation||for||emotion classification)
(Memnet||has||current utterance)
(current utterance||fed to||memory network)
(memory network||where||memories)
(memories||correspond to||preceding utterances)

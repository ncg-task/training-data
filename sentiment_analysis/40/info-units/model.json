{
  "has" : {
    "Model" : {
      "propose" : {
        "novel framework" : {
          "to solve" : {
            "problems" : {
              "in" : "target sentiment analysis"
            }
          },
          "from sentence" : "In this paper , we propose a novel framework to solve the above problems in target sentiment analysis ."
        }
      },
      "has" : {
        "framework" : {
          "first adopts" : {
            "bidirectional LSTM ( BLSTM )" : {
              "to produce" : {
                "memory ( i.e. the states of time steps generated by LSTM )" : {
                  "from" : "input"
                }
              }
            }
          },
          "from sentence" : "Specifically , our framework first adopts a bidirectional LSTM ( BLSTM ) to produce the memory ( i.e. the states of time steps generated by LSTM ) from the input , as bidirectional recurrent neural networks ( RNNs ) were found effective for a similar purpose in machine translation ."
        },
        "memory slices" : {
          "weighted according to" : {
            "relative positions" : {
              "to" : "target"
            }
          },
          "from sentence" : "The memory slices are then weighted according to their relative positions to the target , so that different targets from the same sentence have their own tailor - made memories ."
        },
        "Our framework" : {
          "introduces" : {
            "novel way" : {
              "of applying" : {
                "multiple - attention mechanism" : {
                  "to synthesize" : {
                    "important features" : {
                      "in" : "difficult sentence structures"
                    }
                  }
                }
              }
            }
          },
          "from sentence" : "Our framework introduces a novel way of applying multiple - attention mechanism to synthesize important features in difficult sentence structures ."
        }
      },
      "pay" : {
        "multiple attentions" : {
          "on" : "position - weighted memory"
        }
      },
      "nonlinearly combine" : {
        "attention results" : {
          "with" : "recurrent network , i.e. GRUs"
        },
        "from sentence" : "After that , we pay multiple attentions on the position - weighted memory and nonlinearly combine the attention results with a recurrent network , i.e. GRUs ."        
      },
      "apply" : {
        "softmax" : {
          "on" : {
            "output" : {
              "of" : "GRU network"
            }
          },
          "to predict" : {
            "sentiment" : {
              "on" : "target"
            }          
          }
        },
        "from sentence" : "Finally , we apply softmax on the output of the GRU network to predict the sentiment on the target ."
      }
    }
  }
}
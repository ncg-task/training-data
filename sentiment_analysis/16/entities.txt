229	0	3	AMN
229	8	45	state - of - the - art memory network
229	46	54	used for
229	55	58	ASC
231	0	7	BL - MN
231	10	34	Our basic memory network
231	66	78	does not use
231	83	102	proposed techniques
231	103	116	for capturing
231	117	146	target - sensitive sentiments
232	0	9	AE - LSTM
233	8	20	compare with
233	23	68	state - of - the - art attention - based LSTM
233	69	72	for
233	73	76	ASC
234	0	11	ATAE - LSTM
235	8	30	attention - based LSTM
235	31	34	for
235	35	38	ASC
236	0	43	Target - sensitive Memory Networks ( TMNs )
237	4	27	six proposed techniques
237	30	32	NP
237	35	38	CNP
237	41	43	IT
237	46	48	CI
237	51	54	JCI
237	61	64	JPI
237	65	69	give
237	70	108	six target - sensitive memory networks
247	3	6	use
247	11	40	open - domain word embeddings
247	43	46	for
247	51	65	initialization
247	66	68	of
247	69	81	word vectors
248	3	13	initialize
248	14	36	other model parameters
248	37	41	from
248	44	84	uniform distribution U ( - 0.05 , 0.05 )
249	4	13	dimension
249	70	73	are
249	74	77	300
249	14	16	of
249	21	35	word embedding
249	44	69	size of the hidden layers
250	4	17	learning rate
250	21	27	set to
250	28	32	0.01
250	41	53	dropout rate
250	57	63	set to
250	64	67	0.1
251	0	27	Stochastic gradient descent
251	31	38	used as
251	39	52	our optimizer
253	8	15	compare
253	20	35	memory networks
253	36	38	in
253	45	107	multiple computational layers version ( i.e. , multiple hops )
253	116	130	number of hops
253	134	140	set to
253	141	142	3
254	3	14	implemented
254	15	25	all models
254	26	28	in
254	33	55	TensorFlow environment
254	56	61	using
254	62	123	same input , embedding size , dropout rate , optimizer , etc.
51	29	36	propose
51	37	80	target - sensitive memory networks ( TMNs )
51	89	100	can capture
51	105	126	sentiment interaction
51	127	134	between
51	135	155	targets and contexts
2	39	70	Aspect Sentiment Classification
4	0	39	Aspect sentiment classification ( ASC )
4	65	83	sentiment analysis
8	79	82	ASC
265	0	9	Comparing
265	14	37	1 - hop memory networks
265	63	66	see
265	67	96	significant performance gains
265	97	108	achieved by
265	109	133	CNP , CI , JCI , and JPI
265	134	136	on
265	137	150	both datasets
265	159	175	each of them has
265	176	184	p < 0.01
265	185	189	over
265	194	224	strongest baseline ( BL - MN )
265	225	229	from
265	230	244	paired t- test
265	245	250	using
265	251	261	F1 - Macro
272	14	22	all TMNs
272	28	36	see that
272	37	40	JCI
272	41	46	works
272	51	55	best
268	4	6	In
268	11	26	3 - hop setting
268	29	33	TMNs
268	34	41	achieve
268	42	61	much better results
268	62	64	on
268	65	75	Restaurant
269	0	17	JCI , IT , and CI
269	18	25	achieve
269	30	41	best scores
269	44	57	outperforming
269	62	84	strongest baseline AMN
269	85	87	by
269	88	116	2.38 % , 2.18 % , and 2.03 %
270	0	2	On
270	3	9	Laptop
270	12	33	BL - MN and most TMNs
270	57	64	perform
270	65	74	similarly
273	0	10	CI and JPI
273	16	23	perform
273	24	28	well
273	29	31	in
273	32	42	most cases
274	0	17	IT , NP , and CNP
274	22	29	achieve
274	30	46	very good scores
274	47	49	in
274	50	60	some cases
274	65	68	are
274	69	80	less stable

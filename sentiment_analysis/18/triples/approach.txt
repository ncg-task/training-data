(Contribution||has||Approach)
(Approach||has||first approach)
(first approach||use||autoencoder structure)
(autoencoder structure||to learn||both the aspect embeddings as well as the representation of the target)
(both the aspect embeddings as well as the representation of the target||as||weighted combination)
(weighted combination||of||aspect embeddings)
(first approach||model||each target)
(each target||as||mixture)
(mixture||of||K aspect embeddings)
(first approach||has||autoencoder structure)
(autoencoder structure||jointly trained with||neural attention - based sentiment classifier)
(neural attention - based sentiment classifier||to provide||good target representation)
(good target representation||as well as||high accuracy)
(high accuracy||on||predicted sentiment)
(Approach||has||second approach)
(second approach||has||syntax - based attention mechanism)
(syntax - based attention mechanism||selectively focuses on||small subset of context words)
(small subset of context words||close to||target)
(target||on||syntactic path)
(syntactic path||obtained by||applying a dependency parser)
(applying a dependency parser||on||review sentence)
(second approach||exploits||syntactic information)
(syntactic information||to construct||syntax - based attention model)
(Approach||propose||two novel approaches)
(two novel approaches||for improving||effectiveness of attention models)

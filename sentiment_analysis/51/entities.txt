127	4	19	Word embeddings
128	21	33	word vectors
128	34	47	pretrained on
128	48	65	large text corpus
128	66	73	such as
128	74	88	Wikipedia dump
128	93	108	averaged to get
128	113	128	document vector
128	145	151	fed to
128	156	176	sentiment classifier
128	177	187	to compute
128	192	207	sentiment score
129	4	22	Recursive networks
130	0	50	Various types of recursive neural networks ( RNN )
130	61	71	applied on
130	72	75	SST
133	4	22	Recurrent networks
134	0	32	Sophisticated recurrent networks
134	33	40	such as
134	41	89	left - to - right and bidrectional LSTM networks
134	105	115	applied on
134	116	119	SST
135	4	26	Convolutional networks
136	23	38	input sequences
136	44	58	passed through
136	61	105	1 - dimensional convolutional neural network
136	106	108	as
136	109	127	feature extractors
22	19	22	use
22	27	48	pretrained BERT model
22	53	68	finetune it for
22	73	117	fine - grained sentiment classification task
22	118	120	on
22	125	168	Stanford Sentiment Treebank ( SST ) dataset
2	0	39	Fine - grained Sentiment Classification
4	0	24	Sentiment classification
145	7	15	see that
145	16	25	our model
145	66	74	performs
145	75	81	better
145	82	93	in terms of
145	94	102	accuracy
145	103	107	than
145	108	149	many popular and sophisticated NLP models

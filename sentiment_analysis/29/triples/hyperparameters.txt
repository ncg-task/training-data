(Contribution||has||Hyperparameters)
(Hyperparameters||For||out of vocabulary words)
(out of vocabulary words||initialize them||randomly)
(randomly||from||uniform distribution U ( ? 0.01 , 0.01 ))
(Hyperparameters||has||training loss)
(training loss||does not||drop)
(drop||after||every three epochs)
(drop||decrease||learning rate)
(learning rate||by||half)
(Hyperparameters||has||L 2 regularization coefficient)
(L 2 regularization coefficient||set to||10 ? 4)
(Hyperparameters||has||initial learning rate)
(initial learning rate||is||0.01)
(0.01||for||Adam optimizer)
(Hyperparameters||has||weight matrices)
(weight matrices||randomly initialized from||uniform distribution U ( ?10 ?4 , 10 ?4 ))
(Hyperparameters||has||bias terms)
(bias terms||set to||zero)
(Hyperparameters||has||batch size)
(batch size||set as||25)
(Hyperparameters||has||word embeddings)
(word embeddings||fixed during||training)
(word embeddings||initialized with||300 - dimensional Glove vectors)
(Hyperparameters||has||dropout keep rate)
(dropout keep rate||set to||0.2)
(Hyperparameters||has||dimension)
(dimension||of||LSTM hidden states)
(LSTM hidden states||set to||150)
(Hyperparameters||randomly select||20 %)
(20 %||of||training data)
(training data||as||validation set)
(training data||to tune||hyperparameters)

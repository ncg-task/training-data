27	19	30	investigate
27	31	46	several methods
27	47	49	of
27	50	62	constructing
27	63	65	an
27	66	84	auxiliary sentence
27	89	98	transform
27	99	109	( T ) ABSA
27	110	114	into
27	117	152	sentence - pair classification task
28	3	14	fine - tune
28	19	36	pre-trained model
28	37	41	from
28	42	46	BERT
109	0	2	LR
109	7	37	logistic regression classifier
109	38	42	with
109	43	70	n-gram and pos-tag features
110	0	12	LSTM - Final
110	19	31	biLSTM model
110	32	36	with
110	41	72	final state as a representation
111	0	10	LSTM - Loc
111	17	29	biLSTM model
111	30	34	with
111	39	44	state
111	45	60	associated with
111	65	100	target position as a representation
112	0	14	LSTM + TA + SA
112	21	33	biLSTM model
112	40	50	introduces
112	51	115	complex target - level and sentence - level attention mechanisms
113	0	10	SenticLSTM
113	16	32	upgraded version
113	33	35	of
113	40	60	LSTM + TA + SA model
113	67	77	introduces
113	78	116	external information from Sentic - Net
114	0	12	Dmu - Entnet
114	17	37	bidirectional EntNet
114	38	42	with
114	43	69	external " memory chains "
114	70	74	with
114	77	108	delayed memory update mechanism
114	109	117	to track
114	118	126	entities
100	3	6	use
100	11	48	pre-trained uncased BERT - base model
100	51	54	for
100	55	68	fine - tuning
101	4	32	number of Transformer blocks
101	33	35	is
101	36	38	12
101	45	62	hidden layer size
101	63	65	is
101	66	69	768
101	76	108	number of self - attention heads
101	109	111	is
101	112	114	12
101	125	151	total number of parameters
101	152	155	for
101	160	176	pretrained model
101	177	179	is
101	180	184	110M
106	4	25	initial learning rate
106	26	28	is
106	29	36	2 e - 5
106	47	57	batch size
106	58	60	is
106	61	63	24
105	4	23	dropout probability
105	24	26	at
105	27	30	0.1
105	33	36	set
105	41	57	number of epochs
105	58	60	to
105	61	62	4
2	19	52	Aspect - Based Sentiment Analysis
4	0	42	Aspect - based sentiment analysis ( ABSA )
4	156	181	sentiment analysis ( SA )
16	5	7	SA
16	12	16	ABSA
17	34	86	targeted aspect - based sentiment analysis ( TABSA )
120	13	26	BERT - single
120	31	39	achieved
120	40	54	better results
120	83	94	BERT - pair
120	99	107	achieved
120	108	128	further improvements
120	129	133	over
120	134	147	BERT - single
121	4	31	BERT - pair - NLI - B model
121	32	40	achieves
121	45	61	best performance
121	62	65	for
121	66	91	aspect category detection
122	0	3	For
122	4	28	aspect category polarity
122	31	48	BERTpair - QA - B
122	49	57	performs
122	58	62	best
122	63	65	on
122	66	109	all 4 - way , 3 - way , and binary settings

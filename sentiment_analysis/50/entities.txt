115	16	25	transfers
115	26	28	of
115	33	57	LSTM and embedding layer
115	58	61	are
115	62	73	more useful
115	74	78	than
115	83	95	output layer
117	6	37	Transfer of the embedding layer
117	38	40	is
117	41	53	more helpful
117	54	56	on
117	57	66	D3 and D4
119	0	21	Sentiment information
119	25	51	not adequately captured by
119	52	74	Glo Ve word embeddings
24	37	85	https://github.com/ruidan/Aspect-level-sentiment
87	21	51	300 - dimension Glo Ve vectors
87	61	74	to initialize
87	75	82	E and E
87	83	87	when
87	88	99	pretraining
87	103	120	not conducted for
87	121	142	weight initialization
88	6	13	vectors
88	23	31	used for
88	32	46	initializing E
88	47	49	in
88	54	71	pretraining phase
90	3	18	randomly sample
90	19	23	20 %
90	24	26	of
90	31	53	original training data
90	54	58	from
90	63	82	aspectlevel dataset
90	83	85	as
90	90	105	development set
91	0	3	For
91	4	19	all experiments
91	26	35	dimension
91	36	38	of
91	39	58	LSTM hidden vectors
91	62	68	set to
91	69	72	300
92	23	26	use
92	27	34	dropout
92	35	39	with
92	40	55	probability 0.5
92	56	58	on
92	59	94	sentence / document representations
92	95	101	before
92	106	118	output layer
93	7	14	RMSProp
93	15	17	as
93	22	31	optimizer
93	32	36	with
93	41	51	decay rate
93	52	58	set to
93	59	62	0.9
93	71	89	base learning rate
93	90	96	set to
93	97	102	0.001
94	4	21	mini - batch size
94	25	31	set to
94	32	34	32
21	18	25	explore
21	26	46	two transfer methods
21	47	61	to incorporate
21	75	84	knowledge
21	87	98	pretraining
21	103	122	multi-task learning
2	34	73	Aspect - level Sentiment Classification
100	3	15	observe that
100	16	20	PRET
100	21	23	is
100	24	36	very helpful
100	43	61	consistently gives
100	64	80	1 - 3 % increase
100	81	83	in
100	84	92	accuracy
100	93	97	over
100	98	108	LSTM + ATT
102	0	4	MULT
102	5	10	gives
102	11	30	similar performance
102	31	33	as
102	34	44	LSTM + ATT
102	45	47	on
102	48	57	D1 and D2
103	4	31	combination ( PRET + MULT )
103	41	47	yields
103	48	62	better results
105	10	37	numbers of neutral examples
105	38	40	in
105	45	54	test sets
105	55	57	of
105	58	67	D3 and D4
105	68	71	are
105	72	82	very small

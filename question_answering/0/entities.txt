19	30	46	semantic parsing
19	56	58	to
19	63	70	problem
19	71	73	of
19	74	79	KB QA
21	0	15	Semantic parses
21	23	53	deterministically converted to
21	56	61	query
21	62	72	to extract
21	77	84	answers
21	85	89	from
21	94	96	KB
20	10	13	for
20	14	33	each input question
20	39	48	construct
20	52	105	explicit structural semantic parse ( semantic graph )
34	19	24	adapt
34	25	62	Gated Graph Neural Networks ( GGNNs )
34	80	100	to process and score
34	101	116	semantic parses
171	4	22	Pooled Edges model
171	28	31	use
171	36	40	DCNN
171	41	50	to encode
171	55	90	question and the label of each edge
171	91	93	in
171	98	112	semantic graph
174	0	28	Graph Neural Network ( GNN )
175	69	76	include
175	79	92	model variant
175	93	110	that does not use
175	115	131	gating mechanism
175	136	153	directly computes
175	158	170	hidden state
175	171	173	as
175	176	187	combination
175	20	22	of
175	195	238	activations ( Eq 1 ) and the previous state
176	0	35	Gated Graph Neural Network ( GGNN )
176	54	64	to process
176	65	80	semantic parses
48	0	77	https://github.com/UKPLab/coling2018-graph-neural-networks-question-answering
2	56	89	Knowledge Base Question Answering
11	0	40	Knowledge base question answering ( QA )
15	0	2	QA
19	74	79	KB QA
219	23	25	on
219	30	50	WebQSP - WD data set
220	21	33	graph models
220	34	44	outperform
220	45	61	all other models
220	62	68	across
220	69	99	precision , recall and F-score
220	107	111	GGNN
220	112	119	showing
220	124	144	best over all result
223	4	22	STAGG architecture
223	23	31	delivers
223	36	49	worst results
224	4	21	Single Edge model
224	22	33	outperforms
224	38	69	more complex Pooled Edges model
224	70	72	by
224	75	92	noticeable margin
225	4	24	Single Edge baseline
225	25	32	prefers
225	33	46	simple graphs
225	47	62	that consist of
225	65	76	single edge
225	83	85	is
225	88	101	good strategy
225	102	112	to achieve
225	113	133	higher recall values
229	4	22	Pooled Edges model
229	23	32	maintains
229	35	53	better performance
229	54	60	across
229	61	94	questions of different complexity
229	103	108	shows
229	113	121	benefits
229	122	133	of encoding
229	134	149	all graph edges
228	17	20	for
228	25	56	STAGG and Single Edge baselines
228	61	72	performance
228	73	75	on
228	76	98	more complex questions
228	99	104	drops
228	105	116	compared to
228	121	128	results
228	129	131	on
228	132	149	simpler questions
233	3	11	see that
233	16	26	GGNN model
233	27	33	offers
233	38	50	best results
233	56	58	on
233	59	87	simple and complex questions

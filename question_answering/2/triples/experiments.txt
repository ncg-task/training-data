(Contribution||has||Experiments)
(Experiments||has||MovieQA dataset)
(MovieQA dataset||has||Experimental setup)
(Experimental setup||set||maximum number of frames to consider)
(maximum number of frames to consider||to||F = 10)
(Experimental setup||set||maximum number of subtitle sentences in a clip)
(maximum number of subtitle sentences in a clip||to||K = 100)
(Experimental setup||set||maximum words)
(maximum words||to||V = 10)
(Experimental setup||set||maximum number of movie clips per question)
(maximum number of movie clips per question||to||N = 20)
(Experimental setup||use||AdaDelta optimizer)
(AdaDelta optimizer||with||initial learning rate)
(initial learning rate||of||0.5)
(initial learning rate||trained for||300 epochs)
(AdaDelta optimizer||with||minibatch)
(minibatch||of||16)
(Experimental setup||implement||FVTA network)
(FVTA network||with||modality number)
(modality number||of||2 ( video & text ))
(FVTA network||for||Movie QA task)
(MovieQA dataset||has||Results)
(Results||has||accuracy)
(accuracy||is||0.373)
(0.373||vs||0.363)
(0.373||on||test set)
(accuracy||is||0.410)
(0.410||vs||0.387)
(0.387||by||RWMN)
(0.410||on||validation set)
(Results||has||FVTA)
(FVTA||consistently outperforms||classical attention models)
(classical attention models||including||soft attention)
(classical attention models||including||MCB)
(classical attention models||including||TGIF)
(Results||has||FVTA model)
(FVTA model||achieves||comparable performance)
(comparable performance||to||state - of - the - art result)
(state - of - the - art result||on||MovieQA test server)
(FVTA model||outperforms||all baseline methods)
(Experiments||has||Memex QA)
(Memex QA||has||Experimental setup)
(Experimental setup||encode||GPS locations)
(GPS locations||using||words)
(Experimental setup||concatenate||output)
(output||of||both directions)
(both directions||of||LSTM)
(LSTM||Given||hidden state size)
(hidden state size||of||d)
(d||set to||50)
(LSTM||for||all media documents)
(all media documents||get||context tensor H)
(context tensor H||has||R 2dV KN 6)
(all media documents||get||question matrix Q)
(question matrix Q||has||R 2 d M)
(Experimental setup||use||pre-trained Glo Ve word embeddings)
(pre-trained Glo Ve word embeddings||fixed during||training)
(Experimental setup||use||linear transformation)
(linear transformation||to compress||image feature)
(image feature||into||100 dimensional)
(Experimental setup||use||AdaDelta optimizer)
(Experimental setup||use||initial learning rate)
(initial learning rate||of||0.5)
(0.5||to train for||200 epochs)
(200 epochs||with||dropout rate)
(dropout rate||of||0.3)
(Experimental setup||For||image / video embedding)
(image / video embedding||extract||fixed - size features)
(fixed - size features||using||pre-trained CNN model)
(pre-trained CNN model||name||Inception - ResNet)
(pre-trained CNN model||by concatenating||pool5 layer and classification layer 's output)
(pool5 layer and classification layer 's output||before||softmax)
(Experimental setup||has||bi-directional LSTM)
(bi-directional LSTM||used for||each modality)
(each modality||to obtain||contextual representations)
(Experimental setup||has||questions , textual context and answers)
(questions , textual context and answers||are||tokenized)
(tokenized||using||Stanford word tokenizer)
(Experimental setup||reshape||context tensor)
(context tensor||into||H ? R 2 d T 6)
(Experimental setup||To select||best hyperparmeters)
(best hyperparmeters||randomly select||20 %)
(20 %||of||official training set)
(official training set||as||validation set)
(Memex QA||has||Results)
(Results||has||FVTA)
(FVTA||outperforms||other attention models)
(other attention models||on finding||relevant photos)
(relevant photos||for||question)
(Memex QA||has||Ablation analysis)
(Ablation analysis||compare||effectiveness)
(effectiveness||of||context - aware question attention)
(context - aware question attention||shows||question attention)
(question attention||provides||slight improvement)
(context - aware question attention||by removing||question attention)
(context - aware question attention||use||last timestep)
(last timestep||of||LSTM output)
(LSTM output||as||question representation)
(LSTM output||from||question)
(Ablation analysis||For ablating||intra-sequence dependency)
(intra-sequence dependency||use||representations)
(representations||from||last timestep)
(last timestep||of||each context document)
(Ablation analysis||For ablating||cross sequence interaction)
(cross sequence interaction||average||all attended context representation)
(all attended context representation||from||different modalities)
(different modalities||to get||final context vector)
(Ablation analysis||has||Both aspects of correlation)
(Both aspects of correlation||of||FVTA attention tensor)
(Both aspects of correlation||while||intra-sequence dependency)
(intra-sequence dependency||shows||more importance)
(Both aspects of correlation||contribute towards||model 's performance)
(Ablation analysis||evaluate||FVTA attention mechanism)
(FVTA attention mechanism||first replace||our kernel tensor)
(our kernel tensor||with||simple cosine similarity function)
(our kernel tensor||has||Results)
(Results||show that||standard cosine similarity)
(standard cosine similarity||inferior to||our similarity function)
(Ablation analysis||train||FVTA without photos)
(FVTA without photos||to see||contribution)
(contribution||of||visual information)
(FVTA without photos||has||result)
(result||is||quite good)
(Memex QA||has||Baselines)
(Baselines||has||Embedding + LSTM)
(Embedding + LSTM||utilizes||word embeddings and character embeddings)
(word embeddings and character embeddings||along with||same visual embeddings)
(same visual embeddings||used in||FVTA)
(Baselines||has||Embedding + LSTM + Concat)
(Embedding + LSTM + Concat||concatenates||last LSTM output)
(last LSTM output||from||different modalities)
(different modalities||to produce||final output)
(Baselines||has||Classic Soft Attention)
(Classic Soft Attention||uses||classic one dimensional question - to - context attention)
(classic one dimensional question - to - context attention||to summarize||context)
(context||for||question answering)
(Baselines||has||DMN +)
(DMN +||is||improved dynamic memory networks)
(improved dynamic memory networks||which is one of||representative architectures)
(representative architectures||that achieve||good performance)
(good performance||on||VQA Task)
(Baselines||has||Logistic Regression)
(Logistic Regression||predicts||answer)
(answer||with||concatenated image , question and metadata features)
(Baselines||has||TGIF Temporal Attention)
(TGIF Temporal Attention||is||spatial - temporal reasoning network)
(spatial - temporal reasoning network||on||sequential animated image QA)

{
  "has" : {
    "Experimental setup" : {
      "implement" : {
        "all models" : {
          "in" : "TensorFlow"
        },
        "from sentence" : "We implement all models in TensorFlow ."
      },
      "has" : {
        "Word embeddings" : {
          "initialized with" : "300d Glo Ve vectors",
          "not fine - tuned during" : "training",
          "from sentence" : "Word embeddings are initialized with 300d Glo Ve vectors and are not fine - tuned during training ."
        },
        "Dropout rate" : {
          "tuned amongst" : {
            "{ 0.1 , 0.2 , 0.3 }" : {
              "on" : {
                "all layers" : {
                  "including" : "embedding layer"
                }
              }
            }
          },
          "from sentence" : "Dropout rate is tuned amongst { 0.1 , 0.2 , 0.3 } on all layers including the embedding layer ."
        },
        "batch size" : {
          "set to" : "64/256/32",
          "from sentence" : "The batch size is set to 64/256/32 accordingly ."
        },
        "maximum sequence lengths" : {
          "are" : "500/200/1100",
          "from sentence" : "The maximum sequence lengths are 500/200/1100 respectively ."
        },
        "runtime benchmarks" : {
          "based on" : "TitanXP GPU",
          "from sentence" : "All models are trained and all runtime benchmarks are based on a TitanXP GPU ."
        }
      },
      "adopt" : {
        "Adam optimizer" : {
          "with" : {
            "learning rate" : {
              "of" : {
                "0.0003/ 0.001/0.001" : {
                  "for" : "RACE / SearchQA / Narrative QA"
                }
              }
            }
          },
          "from sentence" : "We adopt the Adam optimizer ( Kingma and Ba , 2014 ) with a learning rate of 0.0003/ 0.001/0.001 for RACE / SearchQA / Narrative QA respectively ."
        }
      },
      "For" : {
        "Narrative QA" : {
          "use" : {
            "Rouge - L score" : {
              "to find" : {
                "best approximate answer" : {
                  "relative to" : {
                    "human written answer" : {
                      "for training" : "span model"
                    }
                  }
                }
              }
            }
          },
          "from sentence" : "For Narrative QA , we use the Rouge - L score to find the best approximate answer relative to the human written answer for training the span model ."
        }
      }
    }
  }
}
(Contribution||has||Results)
(Results||on||NarrativeQA benchmark)
(NarrativeQA benchmark||observe that||300d DCU)
(300d DCU||achieve||comparable performance)
(comparable performance||with||BiDAF)
(NarrativeQA benchmark||has||DCU - LSTM)
(DCU - LSTM||significantly outperforms||all models)
(all models||including||BiDAF)
(all models||in terms of||ROUGE - L)
(NarrativeQA benchmark||has||Performance improvement)
(Performance improvement||over||vanilla BiLSTM model)
(vanilla BiLSTM model||ranges from||1 % ? 3 %)
(1 % ? 3 %||across||all metrics)
(Results||on||RACE benchmark dataset)
(RACE benchmark dataset||pull ahead of||other recent baselines)
(other recent baselines||by||at least 5 %)
(other recent baselines||such as||ElimiNet)
(other recent baselines||such as||GA)
(RACE benchmark dataset||outperform||highly complex models)
(highly complex models||such as||DFN)
(RACE benchmark dataset||has||Our proposed DCU model)
(Our proposed DCU model||achieves||best result)
(best result||for||single models)
(best result||for||ensemble models)
(RACE benchmark dataset||has||best single model score)
(best single model score||from||RACE - H)
(best single model score||from||RACE - M)
(best single model score||alternates between||Sim - DCU)
(best single model score||alternates between||DCU)
(Results||on||Search QA dataset)
(Search QA dataset||achieve||same accuracy)
(same accuracy||as||AMANDA)
(same accuracy||without using||LSTM or GRU encoder)
(Search QA dataset||has||hybrid combination , DCU - LSTM)
(hybrid combination , DCU - LSTM||significantly outperforms||AMANDA)
(AMANDA||by||3 %)
